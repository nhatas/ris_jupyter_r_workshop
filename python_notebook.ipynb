{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e51df8-a5d6-40f5-8e8e-912d10fdefab",
   "metadata": {},
   "source": [
    "# RIS Jupyter and R Data Science Workshop Notebook\n",
    "\n",
    "#### Original notebook modified with permission from [Randal S. Olson](http://www.randalolson.com/)\n",
    "#### Licensed by [Creative Commons](https://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5862e17-baf7-41fd-9dbe-228574b25e42",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "\n",
    "If you are attending this workshop and wish to follow along and submit a job, it is assumed that:\n",
    "* Have been assigned a Wash U WUSTL Key Identity\n",
    "* Are on local Wash U computer networks or have access to the Wash U Medical School VPN\n",
    "* Have read and comply with the [User Agreement](https://docs.ris.wustl.edu/doc/compute/user-agreement.html#ris-user-agreement).\n",
    "* Have some familiarity with Python and/or R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b2350-33c8-4259-ab70-ea23c818bddf",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the time it took you to read this sentence, terabytes of data have been collectively generated across the world — more data than any of us could ever hope to process, much less make sense of, on the machines we're using to read this notebook.\n",
    "\n",
    "In response to this massive influx of data, the field of Data Science has come to the forefront in the past decade. Cobbled together by people from a diverse array of fields — statistics, physics, computer science, design, and many more — the field of Data Science represents our collective desire to understand and harness the abundance of data around us to build a better world.\n",
    "\n",
    "In this notebook, I'm going to go over a basic Python data exploration workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb331bc-eaac-4706-b96d-e6157020f8b8",
   "metadata": {},
   "source": [
    "## The problem\n",
    "\n",
    "For the purposes of this exercise, let's pretend we were recently hired by a lab at WashU. Our first project is to clean up a data file generated by field researchers in our lab for downstream analysis.\n",
    "\n",
    "<img src=\"images/petal_sepal.jpg\" />\n",
    "\n",
    "We've been provided a dataset (iris-data.csv) from our field researchers, which only includes measurements for three types of *Iris* flowers:\n",
    "\n",
    "### *Iris setosa*\n",
    "\n",
    "<img src=\"images/iris_setosa.jpg\" />\n",
    "\n",
    "### *Iris versicolor*\n",
    "<img src=\"images/iris_versicolor.jpg\" />\n",
    "\n",
    "### *Iris virginica*\n",
    "<img src=\"images/iris_virginica.jpg\" />\n",
    "\n",
    "The four measurements we're using currently come from hand-measurements by the field researchers.\n",
    "\n",
    "**Note:** The data set we're working with is the famous [*Iris* data set](https://archive.ics.uci.edu/ml/datasets/Iris) — included with this notebook — modified slightly for demonstration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e169fb-a860-4e6f-bc29-929723306710",
   "metadata": {},
   "source": [
    "## Step 1: Answering the question\n",
    "\n",
    "\n",
    "The first step to any data analysis project is to define the question or problem we're looking to solve, and to define a measure (or set of measures) for our success at solving that task. The data analysis checklist has us answer a handful of questions to accomplish that, so let's work through those questions.\n",
    "\n",
    ">Did you specify the type of data analytic question (e.g. exploration, association causality) before touching the data?\n",
    "\n",
    "We're trying to explore the data provided by the field researchers.\n",
    "\n",
    ">Did you define the metric for success before beginning?\n",
    "\n",
    "Let's do that now. Our PI wants to ensure that there are no missing or mis-labeled data in the data set.\n",
    "\n",
    ">Did you understand the context for the question and the scientific application?\n",
    "\n",
    "We're building part of a larger data analysis pipeline to study three Iris flowers.\n",
    "\n",
    ">Did you record the experimental design?\n",
    "\n",
    "Our PI has told us that the field researchers are hand-measuring 50 randomly-sampled flowers of each species using a standardized methodology. The field researchers take pictures of each flower they sample from pre-defined angles so the measurements and species can be confirmed by the other field researchers at a later point. At the end of each day, the data is compiled and stored on a private lab GitHub repository.\n",
    "\n",
    "<hr />\n",
    "\n",
    "Notice that we've spent a fair amount of time working on the problem without writing a line of code or even looking at the data.\n",
    "\n",
    "**Thinking about and documenting the problem we're working on is an important step to performing effective data analysis that often goes overlooked.** Don't skip it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b5c43-514a-41e8-903d-7ee058119270",
   "metadata": {},
   "source": [
    "## Step 2: Checking the data\n",
    "\n",
    "\n",
    "The next step is to look at the data we're working with. Even curated data sets from the government can have errors in them, and it's vital that we spot these errors before investing too much time in our analysis.\n",
    "\n",
    "Generally, we're looking to answer the following questions:\n",
    "\n",
    "* Is there anything wrong with the data?\n",
    "* Are there any quirks with the data?\n",
    "* Do I need to fix or remove any of the data?\n",
    "\n",
    "Let's start by reading the data into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd23959-2a08-4c88-935c-14b72220b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_data = pd.read_csv('iris-data.csv')\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67294de-405e-44b3-9b17-8b6156652498",
   "metadata": {},
   "source": [
    "**One of the first things we should look for is missing data.** Thankfully, the field researchers already told us that they put a 'NA' into the spreadsheet when they were missing a measurement.\n",
    "\n",
    "We can tell pandas to automatically identify missing values if it knows our missing value marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb22e2-94db-4e13-875e-8133ee909b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.read_csv('iris-data.csv', na_values=['NA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a602a46-ec2f-4277-9d4a-c57dd0396885",
   "metadata": {},
   "source": [
    "Next, it's always a good idea to look at the distribution of our data — especially the outliers.\n",
    "\n",
    "Let's start by printing out some summary statistics about the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e21fc-d31f-426e-b537-bb278b7fb0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236c332-fe45-4798-a154-277cec46b38a",
   "metadata": {},
   "source": [
    "We can see several useful values from this table. For example, we see that five `petal_width_cm` entries are missing.\n",
    "\n",
    "Tables like this are rarely useful unless we know that our data should fall in a particular range. It's usually better to visualize the data in some way.\n",
    "\n",
    "Since we know we're going to be plotting in this section, let's set up the notebook so we can plot inside of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff99a20-6680-4dc3-8930-c40f0429bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line tells the notebook to show plots inside of the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa387b-fa79-48f8-a07f-53a179880cb1",
   "metadata": {},
   "source": [
    "Next, let's create a **scatterplot matrix**. Scatterplot matrices plot the distribution of each column along the diagonal, and then plot a scatterplot matrix for the combination of each variable. They make for an efficient tool to look for errors in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c585a241-c126-4643-b5d7-d39d0c96e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to temporarily drop the rows with 'NA' values\n",
    "# because the Seaborn plotting function does not know\n",
    "# what to do with them\n",
    "sb.pairplot(iris_data.dropna(), hue='class')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf0e46-15b1-4a96-bdcb-43bc7100230d",
   "metadata": {},
   "source": [
    "From the scatterplot matrix, we can already see some issues with the data set.\n",
    "\n",
    "We need to figure out what to do with the erroneous data. Which takes us to the next step..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ff8eb-94f4-4519-955e-0ba42c54c027",
   "metadata": {},
   "source": [
    "## Step 3: Tidying the data\n",
    "\n",
    "Now that we've identified several errors in the data set, we need to fix them before we proceed with the analysis.\n",
    "\n",
    "Let's walk through the issues one-by-one.\n",
    "\n",
    "**There are five classes when there should only be three**\n",
    "\n",
    "Let's use the DataFrame to fix these errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d27f85-a4ea-4528-a9fb-27ce0b4c8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[iris_data['class'] == 'versicolor', 'class'] = 'Iris-versicolor'\n",
    "iris_data.loc[iris_data['class'] == 'Iris-setossa', 'class'] = 'Iris-setosa'\n",
    "\n",
    "iris_data['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ed500-1d69-4e8a-a8e5-396f2fc13d2c",
   "metadata": {},
   "source": [
    "**There are some clear outliers in the measurements that may be erroneous**:\n",
    "\n",
    "In the case of the one anomalous entry for `Iris-setosa`, let's say our field researchers know that it's impossible for `Iris-setosa` to have a sepal width below 2.5 cm. Clearly this entry was made in error, and we're better off just scrapping the entry than spending hours finding out what happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd59580-11cf-455a-a020-223c1e89a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line drops any 'Iris-setosa' rows with a separal width less than 2.5 cm\n",
    "iris_data = iris_data.loc[(iris_data['class'] != 'Iris-setosa') | (iris_data['sepal_width_cm'] >= 2.5)]\n",
    "iris_data.loc[iris_data['class'] == 'Iris-setosa', 'sepal_width_cm'].hist()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5649d57-20a6-4840-98bd-524df04000a3",
   "metadata": {},
   "source": [
    "The next data issue to address is the several near-zero sepal lengths for the `Iris-versicolor` rows. Let's take a look at those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2db489-7256-487a-b0b7-9aab57b25d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[(iris_data['class'] == 'Iris-versicolor') &\n",
    "              (iris_data['sepal_length_cm'] < 1.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a8b0f-f530-4f93-8d00-ff064a347bc0",
   "metadata": {},
   "source": [
    "All of the near-zero `sepal_length_cm` entries seem to be off by two orders of magnitude, as if they had been recorded in meters instead of centimeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6c6a9-5c0a-4964-86f4-6123fb056426",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[(iris_data['class'] == 'Iris-versicolor') &\n",
    "              (iris_data['sepal_length_cm'] < 1.0),\n",
    "              'sepal_length_cm'] *= 100.0\n",
    "\n",
    "iris_data.loc[iris_data['class'] == 'Iris-versicolor', 'sepal_length_cm'].hist()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca362ab-bd59-4610-bea3-7a7f9cf469b6",
   "metadata": {},
   "source": [
    "**We had to drop those rows with missing values.**\n",
    "\n",
    "Let's take a look at the rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa22d2-6bc4-4359-a4ee-4380d01065c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[(iris_data['sepal_length_cm'].isnull()) |\n",
    "              (iris_data['sepal_width_cm'].isnull()) |\n",
    "              (iris_data['petal_length_cm'].isnull()) |\n",
    "              (iris_data['petal_width_cm'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef200296-f360-4b2a-bc2b-a545fb18a29b",
   "metadata": {},
   "source": [
    "One way to deal with missing data is **mean imputation**: If we know that the values for a measurement fall in a certain range, we can fill in empty values with the average of that measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb149a4-230e-4458-84f1-150bbd562ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[iris_data['class'] == 'Iris-setosa', 'petal_width_cm'].hist()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa04d2-2f8b-42a1-a400-a2fb7f6c77c5",
   "metadata": {},
   "source": [
    "Most of the petal widths for `Iris-setosa` fall within the 0.2-0.3 range, so let's fill in these entries with the average measured petal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae2adf-49e2-4427-b5cb-2bf8aa60c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_petal_width = iris_data.loc[iris_data['class'] == 'Iris-setosa', 'petal_width_cm'].mean()\n",
    "\n",
    "iris_data.loc[(iris_data['class'] == 'Iris-setosa') &\n",
    "              (iris_data['petal_width_cm'].isnull()),\n",
    "              'petal_width_cm'] = average_petal_width\n",
    "\n",
    "iris_data.loc[(iris_data['class'] == 'Iris-setosa') &\n",
    "              (iris_data['petal_width_cm'] == average_petal_width)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc1d169-3f77-4915-a255-b043e8bb631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.loc[(iris_data['sepal_length_cm'].isnull()) |\n",
    "              (iris_data['sepal_width_cm'].isnull()) |\n",
    "              (iris_data['petal_length_cm'].isnull()) |\n",
    "              (iris_data['petal_width_cm'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2741ca8-7212-4400-b218-3536202df556",
   "metadata": {},
   "source": [
    "**Note:** If you don't feel comfortable imputing your data, you can drop all rows with missing data with the `dropna()` call:\n",
    "\n",
    "    iris_data.dropna(inplace=True)\n",
    "\n",
    "After all this hard work, we don't want to repeat this process every time we work with the data set. Let's save the tidied data file *as a separate file* and work directly with that data file from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a7f89-fac0-410c-9669-40c4e8aa2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.to_csv('iris-data-clean.csv', index=False)\n",
    "\n",
    "iris_data_clean = pd.read_csv('iris-data-clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2400a598-96ef-4708-b654-f07e2c40c6b3",
   "metadata": {},
   "source": [
    "Now, let's take a look at the scatterplot matrix now that we've tidied the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93d0386-e8ab-427e-8c5f-9fbfd7363443",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(iris_data_clean, hue='class')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1973c4ab-ed89-4bf7-8cb3-68e600d4975d",
   "metadata": {},
   "source": [
    "Numerous errors were purposely into this data set to demonstrate some of the many possible scenarios you may face while tidying your data.\n",
    "\n",
    "The general takeaways here should be:\n",
    "\n",
    "* Make sure your data is encoded properly\n",
    "\n",
    "* Make sure your data falls within the expected range, and use domain knowledge whenever possible to define that expected range\n",
    "\n",
    "* Deal with missing data in one way or another: replace it if you can or drop it\n",
    "\n",
    "* Never tidy your data manually because that is not easily reproducible\n",
    "\n",
    "* Use code as a record of how you tidied your data\n",
    "\n",
    "* Plot everything you can about the data at this stage of the analysis so you can *visually* confirm everything looks correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a3071-906a-4e60-953d-f68a6a63a79d",
   "metadata": {},
   "source": [
    "## Step 4: Exploratory analysis\n",
    "\n",
    "\n",
    "Exploratory analysis is the step where we start delving deeper into the data set beyond the outliers and errors. We'll be looking to answer questions such as:\n",
    "\n",
    "* How is my data distributed?\n",
    "\n",
    "* Are there any correlations in my data?\n",
    "\n",
    "* Are there any confounding factors that explain these correlations?\n",
    "\n",
    "This is the stage where we plot all the data in as many ways as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1001503-60ad-4c7a-be22-e39e83c60b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(iris_data_clean)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff88fc-3517-4a90-a357-4fbcba1ca5c3",
   "metadata": {},
   "source": [
    "Our data is normally distributed for the most part.\n",
    "\n",
    "There's something strange going on with the petal measurements..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22042ca-b061-4152-ba15-96b3abac9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(iris_data_clean, hue='class')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbcbb2c-ee59-4ba3-8b37-d42a3e91d61d",
   "metadata": {},
   "source": [
    "The strange distribution of the petal measurements exist because of the different species.\n",
    "\n",
    "We can also make **violin plots** of the data to compare the measurement distributions of the classes. Violin plots contain the same information as [box plots](https://en.wikipedia.org/wiki/Box_plot), but also scales the box according to the density of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a3fcb-d6e8-4b08-b4d0-92b8d77c2169",
   "metadata": {},
   "source": [
    "## Now What??\n",
    "\n",
    "During today's workshop we performed a basic cleaning and exploration of data to prepare the data for downstream analysis. \n",
    "\n",
    "Possible analyses include:\n",
    "* Classification tasks using machine learning and/or deep learning\n",
    "* Statistical tests to determine if features of each Iris flower are statistically significant from one another"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217e9953-5bab-4dff-bd05-2012c8f6e636",
   "metadata": {},
   "source": [
    "## About this workshop\n",
    "\n",
    "The Docker container used for this workshop was the 'datascience' Docker container maintained by Jupyter https://hub.docker.com/r/jupyter/datascience-notebook/\n",
    "\n",
    "The job submission command to launch this Docker container on the RIS Scientific Compute Platform is\n",
    "\n",
    "    MPLCONFIGDIR=\"$HOME/.local\" JUPYTER_ENABLE_LAB=True LSF_DOCKER_PORTS=\"8888:8888\" LSF_DOCKER_VOLUMES=\"$HOME:$HOME\" PATH=\"/opt/conda/bin:$PATH\" bsub -Is -q general-interactive -R 'select[port8888=1]' -a 'docker(jupyter/datascience-notebook:latest)' /usr/local/bin/start-notebook.sh\n",
    "\n",
    "Please see our [compute-faq](https://docs.ris.wustl.edu/doc/compute/compute-faq.html) for more information on using the Scientific Compute Platform.\n",
    "\n",
    "If you need help using the Scientific Compute Platform, or have questions about any RIS services, please visit our [service desk](https://servicedesk.ris.wustl.edu/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
